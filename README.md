# Medical-CXR-VQA

Medical-CXR-VQA is an LLM-constructed large-scale chest x-ray dataset for the medical visual question answering task. This repository provides the code (currently being organized) for generating the Medical-CXR-VQA dataset, as proposed in our paper, "**Interpretable medical image Visual Question Answering via multi-modal relationship graph learning**."

For more information about the dataset and the method, please refer to our [paper](https://authors.elsevier.com/sd/article/S1361-8415(24)00204-4).

For the code of our multi-modal relationship graph learning method, please refer to [MMRGL](https://github.com/Holipori/MMRGL).

**The Medical-CXR-VQA dataset is currently under review in Physionet. We will attach the link once it's available.**

